{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hi! welcome to the Fwumious Wabbit workshop\n",
    "\n",
    "### Before you start, some prerequisites:\n",
    "\n",
    "This workshop was built and tested on linux and macOS. no guarantees for other operating systems.\n",
    "if you run into issues, or some of the instructions are outdated, feel free to contact me at ykarni@outbrain.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to have [python 3](https://www.python.org/downloads/) installed,\n",
    "and the up-to-date rust tools (rustc, cargo).\n",
    "\n",
    "If you don't have rust, we recommend installing with [rustup](https://rustup.rs/).\n",
    "\n",
    "Create a designated work dir for the workshop.\n",
    "\n",
    "Download the fwumious wabbit code, and build it:\n",
    "\n",
    "(make sure to follow these instructions starting from the directory where you run jupyter notebook from,\n",
    "or use another and just copy the fw binary so that it's available)\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/outbrain/fwumious_wabbit.git\n",
    "cd fwumious_wabbit\n",
    "cargo build --release\n",
    "cp target/release/fw .. # if you didn't start from the desired work dir, replace .. with your work dir\n",
    "cd ..\n",
    "```\n",
    "\n",
    "### If you followed these instructions carefully, fwumious wabbit is now ready to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fwumious wabbit 1.5\r\n",
      "Andraz Tori <atori@outbrain.com>\r\n",
      "Superfast Logistic Regression & Field Aware Factorization Machines\r\n",
      "\r\n",
      "USAGE:\r\n",
      "    fw [FLAGS] [OPTIONS]\r\n",
      "\r\n",
      "FLAGS:\r\n",
      "        --quiet          Quiet mode, does nothing currently (as we don't output diagnostic data anyway)\r\n",
      "    -c, --cache          Use cache file\r\n",
      "        --save_resume    save extra state so learning can be resumed later with new data\r\n",
      "        --sgd            Disable the Adagrad, normalization and invariant updates\r\n",
      "        --adaptive       Use Adagrad\r\n",
      "        --noconstant     No intercept\r\n",
      "    -t, --testonly       Ignore label information and just test\r\n",
      "        --vwcompat       vowpal compatibility mode. Uses slow adagrad, emits warnings for non-compatible features\r\n",
      "        --daemon         read data from port 26542\r\n",
      "        --foreground     in daemon mode, do not fork and run and run fw process in the foreground\r\n",
      "    -h, --help           Prints help information\r\n",
      "    -V, --version        Prints version information\r\n",
      "\r\n",
      "OPTIONS:\r\n",
      "    -d, --data <filename>                                                        File with input examples\r\n",
      "    -p <output predictions file>                                                 Output predictions file\r\n",
      "        --interactions <namespace_char,namespace_char[:value]>...                Adds interactions\r\n",
      "        --linear <verbose_namespace,verbose_namespace[:value]>...\r\n",
      "            Adds linear feature term with optional value\r\n",
      "\r\n",
      "        --keep <namespace>...                                                    Adds single features\r\n",
      "    -l, --learning_rate <0.5>                                                    Learning rate\r\n",
      "        --ffm_learning_rate <0.5>                                                Learning rate\r\n",
      "        --minimum_learning_rate <0.0>\r\n",
      "            Minimum learning rate (in adaptive algos)\r\n",
      "\r\n",
      "        --power_t <0.5>                                                          How to apply Adagrad (0.5 = sqrt)\r\n",
      "        --ffm_power_t <0.5>                                                      How to apply Adagrad (0.5 = sqrt)\r\n",
      "        --l2 <0.0>\r\n",
      "            Regularization is not supported (only 0.0 will work)\r\n",
      "\r\n",
      "        --link <logistic>                                                        What link function to use\r\n",
      "        --loss_function <logistic>                                               What loss function to use\r\n",
      "    -b, --bit_precision <18>\r\n",
      "            Size of the hash space for feature weights\r\n",
      "\r\n",
      "        --hash <all>\r\n",
      "            We do not support treating strings as already hashed numbers, so you have to use --hash all\r\n",
      "\r\n",
      "    -f, --final_regressor <arg>\r\n",
      "            Final regressor to save (arg is filename)\r\n",
      "\r\n",
      "    -i, --initial_regressor <arg>\r\n",
      "            Initial regressor(s) to load into memory (arg is filename)\r\n",
      "\r\n",
      "        --transform <target_namespace=func(source_namespaces)(parameters)>...\r\n",
      "            Create new namespace by transforming one or more other namespaces\r\n",
      "\r\n",
      "        --ffm_field <namespace,namespace,...>...\r\n",
      "            Define a FFM field by listing namespace letters\r\n",
      "\r\n",
      "        --ffm_field_verbose <namespace_verbose,namespace_verbose,...>...\r\n",
      "            Define a FFM field by listing verbose namespace names\r\n",
      "\r\n",
      "        --ffm_k <k>                                                              Lenght of a vector to use for FFM\r\n",
      "        --ffm_bit_precision <N>                                                  Bits to use for ffm hash space\r\n",
      "        --ffm_k_threshold <ffm_k_threshold>\r\n",
      "            A minum gradient on left and right side to increase k\r\n",
      "\r\n",
      "        --ffm_init_center <ffm_init_center>\r\n",
      "            Center of the initial weights distribution\r\n",
      "\r\n",
      "        --ffm_init_width <ffm_init_width>\r\n",
      "            Total width of the initial weights distribution\r\n",
      "\r\n",
      "        --ffm_init_zero_band <ffm_init_zero_band>\r\n",
      "            Percentage of ffm_init_width where init is zero\r\n",
      "\r\n",
      "        --ffm_init_acc_gradient <ffm_init_acc_gradient>\r\n",
      "            Adagrad initial accumulated gradient for ffm\r\n",
      "\r\n",
      "        --init_acc_gradient <init_acc_gradient>\r\n",
      "            Adagrad initial accumulated gradient for \r\n",
      "\r\n",
      "        --port <arg>                                                             port to listen on\r\n",
      "        --num_children <arg (=10>\r\n",
      "            number of children for persistent daemon mode\r\n",
      "\r\n",
      "        --prediction_model_delay <examples (0)>\r\n",
      "            Output predictions with a model that is delayed by a number of examples\r\n",
      "\r\n",
      "        --predictions_after <examples (=0)>\r\n",
      "            After how many examples start printing predictions\r\n",
      "\r\n",
      "        --holdout_after <examples>\r\n",
      "            After how many examples stop updating weights\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!./fw --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the dataset\n",
    "hopefully you already downloaded the dataset files from google drive:\n",
    "\n",
    "https://drive.google.com/drive/folders/1uNpus6CehoamstYh-JFBE_cwbJ-JLizM?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review your working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12420496\r\n",
      "-rw-r--r--@ 1 ykarni  staff   601B Oct 19 13:32 calc_loss.py\r\n",
      "-rw-r--r--@ 1 ykarni  staff   1.4K Oct 19 17:30 create_submission_file.py\r\n",
      "-rw-r--r--  1 ykarni  staff   482M Oct 19 12:26 dev.fw.gz\r\n",
      "-rw-r--r--  1 ykarni  staff    63M Oct 19 13:13 dev_labels\r\n",
      "-rwxr-xr-x  1 ykarni  staff   2.0M Oct 19 13:33 \u001b[31mfw\u001b[m\u001b[m\r\n",
      "-rw-r--r--@ 1 ykarni  staff    53K Oct 21 12:16 fw_ffm_workshop.ipynb\r\n",
      "-rw-r--r--@ 1 ykarni  staff   3.3K Oct 20 13:35 fw_util.py\r\n",
      "-rw-r--r--  1 ykarni  staff   156K Oct 19 13:24 sample.fw\r\n",
      "-rw-r--r--  1 ykarni  staff   884M Oct 19 17:18 test.fw.gz\r\n",
      "-rw-r--r--  1 ykarni  staff   1.9G Oct 19 12:44 train.fw.gz\r\n",
      "-rw-r--r--  1 ykarni  staff   2.4G Oct 19 12:57 train_full.fw.gz\r\n",
      "-rw-r--r--  1 ykarni  staff   253M Oct 19 13:45 train_labels\r\n",
      "-rw-r--r--@ 1 ykarni  staff   261B Oct 19 22:00 vw_namespace_map.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's have a glance at our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is split into train and dev (cross validation), roughly a 80:20 split,\n",
    "\n",
    "with train.fw.gz containing 69,713,384 records, and dev.fw.gz 17,428,347 records.\n",
    "\n",
    "let's examine a single record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 |A 108f172cd134aa |B 2 |C US>MA>506 |D 1 |E 2383841 |F 11680 |G 869 |H 1903 |I 492733 |J 32678 |K 4304 |L 2412693 |M 1822 |N 373 |O |P 1808 1903 |Q 2 |R 10686485\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 1 sample.fw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the namespace map file to understand better what we see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,uuid\r\n",
      "B,platform\r\n",
      "C,geo_location\r\n",
      "D,traffic_source\r\n",
      "E,document_id\r\n",
      "F,source_id\r\n",
      "G,publisher_id\r\n",
      "H,categories\r\n",
      "I,ad_id\r\n",
      "J,campaign_id\r\n",
      "K,advertiser_id\r\n",
      "L,ad_document_id\r\n",
      "M,ad_source_id\r\n",
      "N,ad_publisher_id\r\n",
      "O,ad_categories\r\n",
      "P,user_categories\r\n",
      "Q,user_page_views,f32\r\n",
      "R,display_id\r\n"
     ]
    }
   ],
   "source": [
    "!cat vw_namespace_map.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great! now let's give fwumious wabbit a test drive\n",
    "\n",
    "We'll start by training a simple logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fw_util import train_loop\n",
    "\n",
    "max_iterations = 20\n",
    "print_intermediate_loss = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_args_str = \" \".join([\"--cache\", \\\n",
    "    \"--linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id\", \\\n",
    "    \"--linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id\", \\\n",
    "    \"--linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories\"])\n",
    "\n",
    "optimization_params = \"--adaptive --sgd\"\n",
    "\n",
    "model_name = \"logistic.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train command:\n",
      "./fw --data train.fw.gz --adaptive --sgd --cache --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories -p logistic.1.train_preds --save_resume -f model.logistic.1\n",
      "\n",
      "continue training cmd:\n",
      "./fw --data train.fw.gz --adaptive --sgd --cache --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories -p logistic.1.train_preds --save_resume -f model.logistic.1 -i model.logistic.1\n",
      "\n",
      "cross-validate command:\n",
      "./fw --data dev.fw.gz -i model.logistic.1 --testonly -p logistic.1.dev_preds --cache --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories\n",
      "\n",
      "train loss: 0.44783\tdev loss: 0.43497\ttrain time: 164.2 seconds\n",
      "train loss: 0.43897\tdev loss: 0.43417\ttrain time: 27.7 seconds\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "iterations = train_loop(common_args_str, optimization_params, model_name, max_iterations, print_intermediate_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional step: kaggle submission\n",
    "Let's see how would we fare on the Outbrain click prediction kaggle with this very basic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train command:\n",
      "./fw --data train_full.fw.gz --adaptive --sgd --cache --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories -p logistic.1.train_preds --save_resume -f model.logistic.1\n",
      "\n",
      "continue training command:\n",
      "./fw --data train_full.fw.gz --adaptive --sgd --cache --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories -p logistic.1.train_preds --save_resume -i model.logistic.1\n",
      "\n",
      "test command:\n",
      "./fw --data test.fw.gz -i model.logistic.1 --testonly -p logistic.1.test_preds --cache --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from create_submission_file import create_submission_file\n",
    "from fw_util import create_model_and_predict_for_test_set\n",
    "\n",
    "create_model_and_predict_for_test_set(common_args_str, optimization_params, model_name, iterations)\n",
    "create_submission_file(\"logistic.1.test_preds\", \"logistic.1.submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll drag the output file 'logistic.1.submission.csv' to the target in the Outbrain Kaggle competition \"Late Submission\" form, which you can find here: https://www.kaggle.com/c/outbrain-click-prediction/data,\n",
    "\n",
    "Click \"Upload\" and get the results shortly,\n",
    "\n",
    "and use the Leaderboard to see where this result would place us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we scored 0.64318, which would put as at 265th place out of 978. can we do better?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try some meta-parameter search:\n",
    "Try tweaking the learning rate (\"-l 0.5\") and adagrad smoothing (\"--power_t 0.5\") command line arguments.\n",
    "See if you can get better results just by changing them.\n",
    "\n",
    "Succeeded? great, me too! here's what I have just by trying out a few values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_args_str = \" \".join([\"--cache\", \\\n",
    "    \"--linear uuid --linear platform --linear geo_location --linear traffic_source\", \\\n",
    "    \"--linear document_id --linear source_id --linear publisher_id --linear categories\", \\\n",
    "    \"--linear ad_id --linear campaign_id --linear advertiser_id\", \\\n",
    "    \"--linear ad_document_id --linear ad_source_id --linear ad_publisher_id\", \\\n",
    "    \"--linear ad_categories --linear user_categories\"])\n",
    "\n",
    "optimization_params = \"--adaptive --sgd --power_t 0.2 -l 0.01\"\n",
    "\n",
    "model_name = \"logistic.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train command:\n",
      "./fw --data train.fw.gz --adaptive --sgd --power_t 0.2 -l 0.01 --cache --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories -p logistic.2.train_preds --save_resume -f model.logistic.2\n",
      "\n",
      "continue training cmd:\n",
      "./fw --data train.fw.gz --adaptive --sgd --power_t 0.2 -l 0.01 --cache --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories -p logistic.2.train_preds --save_resume -f model.logistic.2 -i model.logistic.2\n",
      "\n",
      "cross-validate command:\n",
      "./fw --data dev.fw.gz -i model.logistic.2 --testonly -p logistic.2.dev_preds --cache --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories\n",
      "\n",
      "train loss: 0.43523\tdev loss: 0.43314\ttrain time: 25.0 seconds\n",
      "train loss: 0.43330\tdev loss: 0.43285\ttrain time: 24.4 seconds\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "iterations = train_loop(common_args_str, optimization_params, model_name, max_iterations, print_intermediate_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That was nice! time for some namespace-mixing action\n",
    "The big guns! let's try out different feature combinations using the \"--linear namespace_a,namespace_b\" command line argument.\n",
    "\n",
    "Go over the namespace list and try to make an educated guess.\n",
    "\n",
    "How did it go? after some failures, I guessed that combining the publisher_id and advertiser_id might help, and also combining user categories and ad categories, and it did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_args_str = \" \".join([\"--cache\", \\\n",
    "    \"--linear publisher_id,advertiser_id --linear ad_categories,user_categories\", \\\n",
    "    \"--linear uuid --linear platform --linear geo_location --linear traffic_source\", \\\n",
    "    \"--linear document_id --linear source_id --linear publisher_id --linear categories\", \\\n",
    "    \"--linear ad_id --linear campaign_id --linear advertiser_id\", \\\n",
    "    \"--linear ad_document_id --linear ad_source_id --linear ad_publisher_id\", \\\n",
    "    \"--linear ad_categories --linear user_categories\"])\n",
    "\n",
    "optimization_params = \"--adaptive --sgd --power_t 0.2 -l 0.01\"\n",
    "\n",
    "model_name = \"logistic.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train command:\n",
      "./fw --data train.fw.gz --adaptive --sgd --power_t 0.2 -l 0.01 --cache --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories -p logistic.3.train_preds --save_resume -f model.logistic.3\n",
      "\n",
      "continue training cmd:\n",
      "./fw --data train.fw.gz --adaptive --sgd --power_t 0.2 -l 0.01 --cache --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories -p logistic.3.train_preds --save_resume -f model.logistic.3 -i model.logistic.3\n",
      "\n",
      "cross-validate command:\n",
      "./fw --data dev.fw.gz -i model.logistic.3 --testonly -p logistic.3.dev_preds --cache --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories\n",
      "\n",
      "train loss: 0.43087\tdev loss: 0.42809\ttrain time: 26.8 seconds\n",
      "train loss: 0.42799\tdev loss: 0.42759\ttrain time: 26.7 seconds\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "iterations = train_loop(common_args_str, optimization_params, model_name, max_iterations, print_intermediate_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not bad! but we can do better.\n",
    "\n",
    "Do we have collisions? try tweaking the hash space size, using the --bit_precision (or -b) command line argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_args_str = \" \".join([\"--cache -b 25\", \\\n",
    "    \"--linear publisher_id,advertiser_id --linear ad_categories,user_categories\", \\\n",
    "    \"--linear uuid --linear platform --linear geo_location --linear traffic_source\", \\\n",
    "    \"--linear document_id --linear source_id --linear publisher_id --linear categories\", \\\n",
    "    \"--linear ad_id --linear campaign_id --linear advertiser_id\", \\\n",
    "    \"--linear ad_document_id --linear ad_source_id --linear ad_publisher_id\", \\\n",
    "    \"--linear ad_categories --linear user_categories\"])\n",
    "\n",
    "optimization_params = \"--adaptive --sgd --power_t 0.2 -l 0.01\"\n",
    "\n",
    "model_name = \"logistic.4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train command:\n",
      "./fw --data train.fw.gz --adaptive --sgd --power_t 0.2 -l 0.01 --cache -b 25 --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories -p logistic.4.train_preds --save_resume -f model.logistic.4\n",
      "\n",
      "continue training cmd:\n",
      "./fw --data train.fw.gz --adaptive --sgd --power_t 0.2 -l 0.01 --cache -b 25 --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories -p logistic.4.train_preds --save_resume -f model.logistic.4 -i model.logistic.4\n",
      "\n",
      "cross-validate command:\n",
      "./fw --data dev.fw.gz -i model.logistic.4 --testonly -p logistic.4.dev_preds --cache -b 25 --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories\n",
      "\n",
      "train loss: 0.42959\tdev loss: 0.42589\ttrain time: 40.3 seconds\n",
      "train loss: 0.42547\tdev loss: 0.42484\ttrain time: 41.9 seconds\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "iterations = train_loop(common_args_str, optimization_params, model_name, max_iterations, print_intermediate_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nice, it doesn't come free though, we pay with model size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0M, model.logistic.1\r\n",
      "2.0M, model.logistic.2\r\n",
      "2.0M, model.logistic.3\r\n",
      "256M, model.logistic.4\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh model.* | awk -F \" \" '{print $5\", \"$9}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### so, where did logistic regression take us so far?\n",
    "Time for another kaggle submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train command:\n",
      "./fw --data train_full.fw.gz --adaptive --sgd --power_t 0.2 -l 0.01 --cache -b 25 --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories -p logistic.4.train_preds --save_resume -f model.logistic.4\n",
      "\n",
      "continue training command:\n",
      "./fw --data train_full.fw.gz --adaptive --sgd --power_t 0.2 -l 0.01 --cache -b 25 --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories -p logistic.4.train_preds --save_resume -i model.logistic.4\n",
      "\n",
      "test command:\n",
      "./fw --data test.fw.gz -i model.logistic.4 --testonly -p logistic.4.test_preds --cache -b 25 --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from create_submission_file import create_submission_file\n",
    "from fw_util import create_model_and_predict_for_test_set\n",
    "\n",
    "create_model_and_predict_for_test_set(common_args_str, optimization_params, model_name, iterations)\n",
    "create_submission_file(\"logistic.4.test_preds\", \"logistic.4.submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We scored 0.65563, which would place us at 166th place out of 978.** nice improvement of 99 places - logistic regression with feature combinations can go a long way for our use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweet! but we want to see some FFM action please...\n",
    "Let's try to go all-in, and have a field for each namespace:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_args_str = \" \".join([\"--cache -b 25 --ffm_k 2 --ffm_bit_precision 25\", \\\n",
    "    \"--linear publisher_id,advertiser_id --linear ad_categories,user_categories\", \\\n",
    "    \"--linear uuid --linear platform --linear geo_location --linear traffic_source\", \\\n",
    "    \"--linear document_id --linear source_id --linear publisher_id --linear categories\", \\\n",
    "    \"--linear ad_id --linear campaign_id --linear advertiser_id\", \\\n",
    "    \"--linear ad_document_id --linear ad_source_id --linear ad_publisher_id\", \\\n",
    "    \"--linear ad_categories --linear user_categories\", \\\n",
    "    \"--ffm_field_verbose uuid --ffm_field_verbose platform --ffm_field_verbose geo_location\", \\\n",
    "    \"--ffm_field_verbose traffic_source --ffm_field_verbose document_id\", \\\n",
    "    \"--ffm_field_verbose source_id --ffm_field_verbose publisher_id\", \\\n",
    "    \"--ffm_field_verbose categories --ffm_field_verbose ad_id --ffm_field_verbose campaign_id\", \\\n",
    "    \"--ffm_field_verbose advertiser_id --ffm_field_verbose ad_document_id\", \\\n",
    "    \"--ffm_field_verbose ad_source_id --ffm_field_verbose ad_publisher_id\", \\\n",
    "    \"--ffm_field_verbose ad_categories --ffm_field_verbose user_categories\"])\n",
    "\n",
    "optimization_params = \"--adaptive --sgd --power_t 0.2 --ffm_power_t 0.2 -l 0.01 --ffm_learning_rate 0.01\"\n",
    "\n",
    "model_name = \"ffm.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train command:\n",
      "./fw --data train.fw.gz --adaptive --sgd --power_t 0.2 --ffm_power_t 0.2 -l 0.01 --ffm_learning_rate 0.01 --cache -b 25 --ffm_k 2 --ffm_bit_precision 25 --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories --ffm_field_verbose uuid --ffm_field_verbose platform --ffm_field_verbose geo_location --ffm_field_verbose traffic_source --ffm_field_verbose document_id --ffm_field_verbose source_id --ffm_field_verbose publisher_id --ffm_field_verbose categories --ffm_field_verbose ad_id --ffm_field_verbose campaign_id --ffm_field_verbose advertiser_id --ffm_field_verbose ad_document_id --ffm_field_verbose ad_source_id --ffm_field_verbose ad_publisher_id --ffm_field_verbose ad_categories --ffm_field_verbose user_categories -p ffm.1.train_preds --save_resume -f model.ffm.1\n",
      "\n",
      "continue training cmd:\n",
      "./fw --data train.fw.gz --adaptive --sgd --power_t 0.2 --ffm_power_t 0.2 -l 0.01 --ffm_learning_rate 0.01 --cache -b 25 --ffm_k 2 --ffm_bit_precision 25 --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories --ffm_field_verbose uuid --ffm_field_verbose platform --ffm_field_verbose geo_location --ffm_field_verbose traffic_source --ffm_field_verbose document_id --ffm_field_verbose source_id --ffm_field_verbose publisher_id --ffm_field_verbose categories --ffm_field_verbose ad_id --ffm_field_verbose campaign_id --ffm_field_verbose advertiser_id --ffm_field_verbose ad_document_id --ffm_field_verbose ad_source_id --ffm_field_verbose ad_publisher_id --ffm_field_verbose ad_categories --ffm_field_verbose user_categories -p ffm.1.train_preds --save_resume -f model.ffm.1 -i model.ffm.1\n",
      "\n",
      "cross-validate command:\n",
      "./fw --data dev.fw.gz -i model.ffm.1 --testonly -p ffm.1.dev_preds --cache -b 25 --ffm_k 2 --ffm_bit_precision 25 --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories --ffm_field_verbose uuid --ffm_field_verbose platform --ffm_field_verbose geo_location --ffm_field_verbose traffic_source --ffm_field_verbose document_id --ffm_field_verbose source_id --ffm_field_verbose publisher_id --ffm_field_verbose categories --ffm_field_verbose ad_id --ffm_field_verbose campaign_id --ffm_field_verbose advertiser_id --ffm_field_verbose ad_document_id --ffm_field_verbose ad_source_id --ffm_field_verbose ad_publisher_id --ffm_field_verbose ad_categories --ffm_field_verbose user_categories\n",
      "\n",
      "train loss: 0.42390\tdev loss: 0.41837\ttrain time: 169.3 seconds\n",
      "train loss: 0.41666\tdev loss: 0.41646\ttrain time: 191.9 seconds\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "iterations = train_loop(common_args_str, optimization_params, model_name, max_iterations, print_intermediate_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFM models are even bigger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512M, model.ffm.1\r\n",
      "2.0M, model.logistic.1\r\n",
      "2.0M, model.logistic.2\r\n",
      "2.0M, model.logistic.3\r\n",
      "256M, model.logistic.4\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh model.* | awk -F \" \" '{print $5\", \"$9}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we improve further by tweaking the meta parameters?\n",
    "We sure can, BUT I will leave most of the tweaks for you to experiment with. only change here is using ffm_k (the latent vector length) from 2 to 4 - but consider more tweaks:\n",
    "* Divide the fields to smaller groups, for example '--ffm_field_verbose uuid,platform,document_id --ffm_field_verbose ad_categories,categories,user_categories'\n",
    "* Get rid of features in the linear part if they don't help (--interaction blah)\n",
    "* You can still add more feature combinations!\n",
    "* Tweak ffm_power_t, ffm_learning_rate for the optimization process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_args_str = \" \".join([\"--cache -b 25 --ffm_k 2 --ffm_bit_precision 25\", \\\n",
    "    \"--linear publisher_id,advertiser_id --linear ad_categories,user_categories\", \\\n",
    "    \"--linear uuid --linear platform --linear geo_location --linear traffic_source\", \\\n",
    "    \"--linear document_id --linear source_id --linear publisher_id --linear categories\", \\\n",
    "    \"--linear ad_id --linear campaign_id --linear advertiser_id\", \\\n",
    "    \"--linear ad_document_id --linear ad_source_id --linear ad_publisher_id\", \\\n",
    "    \"--linear ad_categories --linear user_categories\", \\\n",
    "    \"--ffm_field_verbose uuid --ffm_field_verbose platform --ffm_field_verbose geo_location\", \\\n",
    "    \"--ffm_field_verbose traffic_source --ffm_field_verbose document_id\", \\\n",
    "    \"--ffm_field_verbose source_id --ffm_field_verbose publisher_id\", \\\n",
    "    \"--ffm_field_verbose categories --ffm_field_verbose ad_id --ffm_field_verbose campaign_id\", \\\n",
    "    \"--ffm_field_verbose advertiser_id --ffm_field_verbose ad_document_id\", \\\n",
    "    \"--ffm_field_verbose ad_source_id --ffm_field_verbose ad_publisher_id\", \\\n",
    "    \"--ffm_field_verbose ad_categories --ffm_field_verbose user_categories\"])\n",
    "\n",
    "optimization_params = \"--adaptive --sgd --power_t 0.2 --ffm_power_t 0.2 -l 0.01 --ffm_learning_rate 0.01\"\n",
    "\n",
    "model_name = \"ffm.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train command:\n",
      "./fw --data train.fw.gz --adaptive --sgd --power_t 0.2 --ffm_power_t 0.2 -l 0.01 --ffm_learning_rate 0.01 --cache -b 25 --ffm_k 2 --ffm_bit_precision 25 --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories --ffm_field_verbose uuid --ffm_field_verbose platform --ffm_field_verbose geo_location --ffm_field_verbose traffic_source --ffm_field_verbose document_id --ffm_field_verbose source_id --ffm_field_verbose publisher_id --ffm_field_verbose categories --ffm_field_verbose ad_id --ffm_field_verbose campaign_id --ffm_field_verbose advertiser_id --ffm_field_verbose ad_document_id --ffm_field_verbose ad_source_id --ffm_field_verbose ad_publisher_id --ffm_field_verbose ad_categories --ffm_field_verbose user_categories -p ffm.2.train_preds --save_resume -f model.ffm.2\n",
      "\n",
      "continue training cmd:\n",
      "./fw --data train.fw.gz --adaptive --sgd --power_t 0.2 --ffm_power_t 0.2 -l 0.01 --ffm_learning_rate 0.01 --cache -b 25 --ffm_k 2 --ffm_bit_precision 25 --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories --ffm_field_verbose uuid --ffm_field_verbose platform --ffm_field_verbose geo_location --ffm_field_verbose traffic_source --ffm_field_verbose document_id --ffm_field_verbose source_id --ffm_field_verbose publisher_id --ffm_field_verbose categories --ffm_field_verbose ad_id --ffm_field_verbose campaign_id --ffm_field_verbose advertiser_id --ffm_field_verbose ad_document_id --ffm_field_verbose ad_source_id --ffm_field_verbose ad_publisher_id --ffm_field_verbose ad_categories --ffm_field_verbose user_categories -p ffm.2.train_preds --save_resume -f model.ffm.2 -i model.ffm.2\n",
      "\n",
      "cross-validate command:\n",
      "./fw --data dev.fw.gz -i model.ffm.2 --testonly -p ffm.2.dev_preds --cache -b 25 --ffm_k 2 --ffm_bit_precision 25 --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories --ffm_field_verbose uuid --ffm_field_verbose platform --ffm_field_verbose geo_location --ffm_field_verbose traffic_source --ffm_field_verbose document_id --ffm_field_verbose source_id --ffm_field_verbose publisher_id --ffm_field_verbose categories --ffm_field_verbose ad_id --ffm_field_verbose campaign_id --ffm_field_verbose advertiser_id --ffm_field_verbose ad_document_id --ffm_field_verbose ad_source_id --ffm_field_verbose ad_publisher_id --ffm_field_verbose ad_categories --ffm_field_verbose user_categories\n",
      "\n",
      "train loss: 0.42390\tdev loss: 0.41837\ttrain time: 169.0 seconds\n",
      "train loss: 0.41666\tdev loss: 0.41646\ttrain time: 167.7 seconds\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "iterations = train_loop(common_args_str, optimization_params, model_name, max_iterations, print_intermediate_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fresh from the oven: feature binning for numerical features\n",
    "We haven't touched the numerical feature \"user_page_views\" yet. in the presentation we saw the numerical feature binning capability in Fwumious Wabbit - let's try it out.\n",
    "\n",
    "The user_page_views feature has the count of user page views before the display event of the recommendation candidate.\n",
    "a user may have seen 0, 1, 4, 12, 30 or any old number in between or a bit above that.\n",
    "\n",
    "We'll use BinnerSqrt with a max value of 10, and resolution=1 - you can tweak those numbers to see if you can get better results.\n",
    "\n",
    "After defining the new feature (--transform), we can use it either in the linear part, alone or as part of an interaction - or as we do here: as a new field.\n",
    "\n",
    "Let's see if it will improve our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_args_str = \" \".join([\"--cache -b 25 --ffm_k 4 --ffm_bit_precision 25\", \\\n",
    "    \"--transform page_views_sqrt=BinnerSqrt(user_page_views)(10,1)\", \\\n",
    "    \"--linear publisher_id,advertiser_id --linear ad_categories,user_categories\", \\\n",
    "    \"--linear uuid --linear platform --linear geo_location --linear traffic_source\", \\\n",
    "    \"--linear document_id --linear source_id --linear publisher_id --linear categories\", \\\n",
    "    \"--linear ad_id --linear campaign_id --linear advertiser_id\", \\\n",
    "    \"--linear ad_document_id --linear ad_source_id --linear ad_publisher_id\", \\\n",
    "    \"--linear ad_categories --linear user_categories\", \\\n",
    "    \"--ffm_field_verbose uuid --ffm_field_verbose platform --ffm_field_verbose geo_location\", \\\n",
    "    \"--ffm_field_verbose traffic_source --ffm_field_verbose document_id\", \\\n",
    "    \"--ffm_field_verbose source_id --ffm_field_verbose publisher_id\", \\\n",
    "    \"--ffm_field_verbose categories --ffm_field_verbose ad_id --ffm_field_verbose campaign_id\", \\\n",
    "    \"--ffm_field_verbose advertiser_id --ffm_field_verbose ad_document_id\", \\\n",
    "    \"--ffm_field_verbose ad_source_id --ffm_field_verbose ad_publisher_id\", \\\n",
    "    \"--ffm_field_verbose ad_categories --ffm_field_verbose user_categories --ffm_field_verbose page_views_sqrt\"])\n",
    "\n",
    "optimization_params = \"--adaptive --sgd --power_t 0.2 --ffm_power_t 0.2 -l 0.01 --ffm_learning_rate 0.01\"\n",
    "\n",
    "model_name = \"ffm.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train command:\n",
      "./fw --data train.fw.gz --adaptive --sgd --power_t 0.2 --ffm_power_t 0.2 -l 0.01 --ffm_learning_rate 0.01 --cache -b 25 --ffm_k 4 --ffm_bit_precision 25 --transform page_views_sqrt=BinnerSqrt(user_page_views)(10,1) --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories --ffm_field_verbose uuid --ffm_field_verbose platform --ffm_field_verbose geo_location --ffm_field_verbose traffic_source --ffm_field_verbose document_id --ffm_field_verbose source_id --ffm_field_verbose publisher_id --ffm_field_verbose categories --ffm_field_verbose ad_id --ffm_field_verbose campaign_id --ffm_field_verbose advertiser_id --ffm_field_verbose ad_document_id --ffm_field_verbose ad_source_id --ffm_field_verbose ad_publisher_id --ffm_field_verbose ad_categories --ffm_field_verbose user_categories --ffm_field_verbose page_views_sqrt -p ffm.3.train_preds --save_resume -f model.ffm.3\n",
      "\n",
      "continue training cmd:\n",
      "./fw --data train.fw.gz --adaptive --sgd --power_t 0.2 --ffm_power_t 0.2 -l 0.01 --ffm_learning_rate 0.01 --cache -b 25 --ffm_k 4 --ffm_bit_precision 25 --transform page_views_sqrt=BinnerSqrt(user_page_views)(10,1) --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories --ffm_field_verbose uuid --ffm_field_verbose platform --ffm_field_verbose geo_location --ffm_field_verbose traffic_source --ffm_field_verbose document_id --ffm_field_verbose source_id --ffm_field_verbose publisher_id --ffm_field_verbose categories --ffm_field_verbose ad_id --ffm_field_verbose campaign_id --ffm_field_verbose advertiser_id --ffm_field_verbose ad_document_id --ffm_field_verbose ad_source_id --ffm_field_verbose ad_publisher_id --ffm_field_verbose ad_categories --ffm_field_verbose user_categories --ffm_field_verbose page_views_sqrt -p ffm.3.train_preds --save_resume -f model.ffm.3 -i model.ffm.3\n",
      "\n",
      "cross-validate command:\n",
      "./fw --data dev.fw.gz -i model.ffm.3 --testonly -p ffm.3.dev_preds --cache -b 25 --ffm_k 4 --ffm_bit_precision 25 --transform page_views_sqrt=BinnerSqrt(user_page_views)(10,1) --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories --ffm_field_verbose uuid --ffm_field_verbose platform --ffm_field_verbose geo_location --ffm_field_verbose traffic_source --ffm_field_verbose document_id --ffm_field_verbose source_id --ffm_field_verbose publisher_id --ffm_field_verbose categories --ffm_field_verbose ad_id --ffm_field_verbose campaign_id --ffm_field_verbose advertiser_id --ffm_field_verbose ad_document_id --ffm_field_verbose ad_source_id --ffm_field_verbose ad_publisher_id --ffm_field_verbose ad_categories --ffm_field_verbose user_categories --ffm_field_verbose page_views_sqrt\n",
      "\n",
      "train loss: 0.42335\tdev loss: 0.41764\ttrain time: 275.7 seconds\n",
      "train loss: 0.41553\tdev loss: 0.41563\ttrain time: 306.9 seconds\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "iterations = train_loop(common_args_str, optimization_params, model_name, max_iterations, print_intermediate_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To wrap things up, let's see where we are now on Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train command:\n",
      "./fw --data train_full.fw.gz --adaptive --sgd --power_t 0.2 --ffm_power_t 0.2 -l 0.01 --ffm_learning_rate 0.01 --cache -b 25 --ffm_k 4 --ffm_bit_precision 25 --transform page_views_sqrt=BinnerSqrt(user_page_views)(10,1) --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories --ffm_field_verbose uuid --ffm_field_verbose platform --ffm_field_verbose geo_location --ffm_field_verbose traffic_source --ffm_field_verbose document_id --ffm_field_verbose source_id --ffm_field_verbose publisher_id --ffm_field_verbose categories --ffm_field_verbose ad_id --ffm_field_verbose campaign_id --ffm_field_verbose advertiser_id --ffm_field_verbose ad_document_id --ffm_field_verbose ad_source_id --ffm_field_verbose ad_publisher_id --ffm_field_verbose ad_categories --ffm_field_verbose user_categories --ffm_field_verbose page_views_sqrt -p ffm.3.train_preds --save_resume -f model.ffm.3\n",
      "\n",
      "continue training command:\n",
      "./fw --data train_full.fw.gz --adaptive --sgd --power_t 0.2 --ffm_power_t 0.2 -l 0.01 --ffm_learning_rate 0.01 --cache -b 25 --ffm_k 4 --ffm_bit_precision 25 --transform page_views_sqrt=BinnerSqrt(user_page_views)(10,1) --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories --ffm_field_verbose uuid --ffm_field_verbose platform --ffm_field_verbose geo_location --ffm_field_verbose traffic_source --ffm_field_verbose document_id --ffm_field_verbose source_id --ffm_field_verbose publisher_id --ffm_field_verbose categories --ffm_field_verbose ad_id --ffm_field_verbose campaign_id --ffm_field_verbose advertiser_id --ffm_field_verbose ad_document_id --ffm_field_verbose ad_source_id --ffm_field_verbose ad_publisher_id --ffm_field_verbose ad_categories --ffm_field_verbose user_categories --ffm_field_verbose page_views_sqrt -p ffm.3.train_preds --save_resume -i model.ffm.3\n",
      "\n",
      "test command:\n",
      "./fw --data test.fw.gz -i model.ffm.3 --testonly -p ffm.3.test_preds --cache -b 25 --ffm_k 4 --ffm_bit_precision 25 --transform page_views_sqrt=BinnerSqrt(user_page_views)(10,1) --linear publisher_id,advertiser_id --linear ad_categories,user_categories --linear uuid --linear platform --linear geo_location --linear traffic_source --linear document_id --linear source_id --linear publisher_id --linear categories --linear ad_id --linear campaign_id --linear advertiser_id --linear ad_document_id --linear ad_source_id --linear ad_publisher_id --linear ad_categories --linear user_categories --ffm_field_verbose uuid --ffm_field_verbose platform --ffm_field_verbose geo_location --ffm_field_verbose traffic_source --ffm_field_verbose document_id --ffm_field_verbose source_id --ffm_field_verbose publisher_id --ffm_field_verbose categories --ffm_field_verbose ad_id --ffm_field_verbose campaign_id --ffm_field_verbose advertiser_id --ffm_field_verbose ad_document_id --ffm_field_verbose ad_source_id --ffm_field_verbose ad_publisher_id --ffm_field_verbose ad_categories --ffm_field_verbose user_categories --ffm_field_verbose page_views_sqrt\n",
      "\n",
      "creating submission file from predictions\n",
      "all done! good luck.\n"
     ]
    }
   ],
   "source": [
    "from create_submission_file import create_submission_file\n",
    "from fw_util import create_model_and_predict_for_test_set\n",
    "\n",
    "create_model_and_predict_for_test_set(common_args_str, optimization_params, model_name, iterations)\n",
    "\n",
    "print(\"creating submission file from predictions\")\n",
    "create_submission_file(\"ffm.3.test_preds\", \"ffm.3.submission.csv\")\n",
    "print(\"all done! good luck.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scored 0.66619 which would place us on 106th place - 60 places up.\n",
    "\n",
    "Can you do better? if you want to play in the big league you'll probably need to do some more work on the dataset though.\n",
    "\n",
    "GOOD LUCK!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
